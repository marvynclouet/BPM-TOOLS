import { NextResponse } from 'next/server'
import { generateText } from 'ai'
import { getAnomalyContextForAI } from '@/lib/anomaly-context'
import { requireAuth } from '@/lib/auth'
import { getReportModel, isRateLimitError, RATE_LIMIT_MESSAGE } from '@/lib/ai-model'
import { getCachedReport, setCachedReport } from '@/lib/ai-report-cache'

/**
 * Analyse anomalies via IA. Cache serveur 1h.
 */
export async function GET() {
  try {
    await requireAuth()

    const cached = await getCachedReport('anomaly')
    if (cached) return NextResponse.json({ report: cached })

    const model = getReportModel()
    if (!model) {
      return NextResponse.json(
        { error: 'Aucune cl√© API IA configur√©e' },
        { status: 503 }
      )
    }

    const context = await getAnomalyContextForAI()
    const prompt = `Tu es l'assistant IA de BPM Formation (CRM formations beatmaking et ing√©nierie du son).

Voici des donn√©es extraites de la base. ANALYSE tout et D√âTECTE les anomalies et incoh√©rences.

R√®gles :
- Liste chaque anomalie / incoh√©rence trouv√©e, avec un titre court et une explication
- Priorise par gravit√© (bloquant ‚Üí important ‚Üí mineur)
- Utilise des emojis (üî¥ ‚ö†Ô∏è üü°) pour la gravit√©
- Propose une action correctrice pour chaque anomalie
- R√©ponds en fran√ßais, style direct et actionnable
- Pas de ** pour le gras
- Si tout est OK, dis-le clairement

--- DONN√âES ---
${context}
--- FIN ---`

    const { text } = await generateText({ model, prompt })
    const report = text.trim()
    await setCachedReport('anomaly', report)
    return NextResponse.json({ report })
  } catch (err: any) {
    console.error('anomaly-report:', err)
    const status = isRateLimitError(err) ? 429 : 500
    const friendlyMsg = isRateLimitError(err) ? RATE_LIMIT_MESSAGE : (err.message || "Erreur lors de l'analyse")
    return NextResponse.json({ error: friendlyMsg }, { status })
  }
}
