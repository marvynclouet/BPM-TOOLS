import { NextRequest, NextResponse } from 'next/server'
import { streamText } from 'ai'
import { xai } from '@ai-sdk/xai'
import { groq } from '@ai-sdk/groq'
import { google } from '@ai-sdk/google'
import { getDashboardContextForAI } from '@/lib/dashboard-context'
import { BPM_TOOLS_KNOWLEDGE } from '@/lib/bpm-tools-knowledge'

const SYSTEM_PROMPT = `Tu es l'assistant IA de BPM Formation, un CRM de formations (beatmaking, ing√©nierie du son). Tu connais tout sur BPM Tools et tu aides l'√©quipe √† l'utiliser.

## Style de r√©ponse (OBLIGATOIRE) :
- Utilise des EMOJIS pour structurer et rendre clair (üìã üîç üì§ ‚úÖ etc.) ‚Äì pas d'ast√©risques pour le gras
- Ne JAMAIS utiliser **pour mettre en gras** ‚Äì remplace par des emojis
- √ânum√®re avec des num√©ros ou des tirets, style direct et lisible
- Phrases courtes, pas de blabla

## Tu dois :
- R√©pondre aux questions "Comment faire X ?", "O√π trouver Y ?" en t'appuyant sur la doc
- Analyser les donn√©es : leads, relances, commentaires, performance
- Alerter sur les relances (leads appel√©s sans action 5+ jours)
- Donner des conseils concrets, √™tre direct et actionnable
- Si on te demande un message de relance WhatsApp : g√©n√®re-le directement en t'appuyant sur les noms des leads √† relancer du contexte
- R√©pondre en fran√ßais

IMPORTANT : Inclus toujours les chemins cliquables dans tes r√©ponses : /dashboard, /dashboard/crm, /dashboard/gestion, /dashboard/planning, /dashboard/comptabilite. Exemple : "Va dans Gestion (/dashboard/gestion) puis..."

## Documentation BPM Tools :

${BPM_TOOLS_KNOWLEDGE}

Lorsque l'utilisateur pose une question sur l'utilisation du site, r√©ponds en t'appuyant sur cette doc. Pour les questions sur les donn√©es (stats, leads, CA), utilise le contexte fourni dans le prompt.`

function getModel() {
  // Priorit√© : Grok (xAI) > Groq > Google Gemini
  if (process.env.XAI_API_KEY) {
    return { model: xai('grok-3-mini'), provider: 'grok' }
  }
  if (process.env.GROQ_API_KEY) {
    return { model: groq('llama-3.3-70b-versatile'), provider: 'groq' }
  }
  if (process.env.GOOGLE_GENERATIVE_AI_API_KEY) {
    return { model: google('gemini-2.0-flash'), provider: 'gemini' }
  }
  return null
}

export async function POST(request: NextRequest) {
  try {
    const modelInfo = getModel()
    if (!modelInfo) {
      return NextResponse.json(
        { error: 'Aucune cl√© API configur√©e. Ajoute GROQ_API_KEY (gratuit), XAI_API_KEY ou GOOGLE_GENERATIVE_AI_API_KEY dans .env' },
        { status: 503 }
      )
    }

    const body = await request.json().catch(() => ({}))
    const userMessage = typeof body.message === 'string' ? body.message.trim() : ''
    const isInitialSynthesis = !userMessage || userMessage.toLowerCase() === 'synth√®se' || userMessage.toLowerCase() === 'resume'

    const context = await getDashboardContextForAI()

    const prompt = isInitialSynthesis
      ? `Voici les donn√©es actuelles du dashboard. G√©n√®re une synth√®se concise qui :
1. D√©crit l'activit√© r√©cente (nouveaux leads, commentaires)
2. Met en √©vidence les relances urgentes si applicable
3. R√©sume la performance (CA, tendances semaine)
4. Donne 1 √† 3 recommandations prioritaires

--- DONN√âES ---
${context}
--- FIN DONN√âES ---`
      : `Contexte √† jour du dashboard :
${context}

Question de l'utilisateur : ${userMessage}

R√©ponds de mani√®re concise et actionnable.`

    const result = streamText({
      model: modelInfo.model,
      system: SYSTEM_PROMPT,
      prompt,
    })

    return result.toTextStreamResponse()
  } catch (error: any) {
    console.error('AI chat error:', error)
    return NextResponse.json(
      { error: error.message || 'Erreur lors de la g√©n√©ration' },
      { status: 500 }
    )
  }
}
